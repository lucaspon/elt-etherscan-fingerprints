{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw0fBt1dR8wR"
      },
      "source": [
        "# Fingeprints DB ELT Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "YnTUZ36GH5d2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "\n",
        "# pd.set_option('display.float_format', lambda x: '%.2f' % x) # suppress scientific notation\n",
        "pd.set_option('display.max_rows', 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Input Addresses and Desired Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add relevant addresses below\n",
        "addresses = {}\n",
        "\n",
        "addresses['FP Main'] = '0xbc49de68bcbd164574847a7ced47e7475179c76b'\n",
        "addresses['FP OPEX'] = '0xc9044dd6162106edb5ece3af8a8e8b657b612e42'\n",
        "addresses['HW Phase3'] = '0x45e77e6473676ab30ed64f3815fea7847d02d7b8'\n",
        "addresses['HW Compensation'] = '0x7af805dcd0c18ed276f99d83197fe7a9d37b3c54'\n",
        "addresses['HW Panels Competition'] = '0xf358e6b648579Bc43042B3cc7661dD5309EB06b3'\n",
        "\n",
        "\n",
        "# don't mess with txtypes!\n",
        "txtypes = {}\n",
        "\n",
        "txtypes['normal'] = 'txlist'\n",
        "txtypes['erc20'] = 'tokentx'\n",
        "txtypes['nfts'] = 'tokennfttx'\n",
        "txtypes['internal'] = 'txlistinternal'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get Last Block from Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv('.env')\n",
        "DB_CREDS = os.environ.get('DB_CREDS')\n",
        "\n",
        "# connect\n",
        "conn = psycopg2.connect(DB_CREDS)\n",
        "cur = conn.cursor()\n",
        "\n",
        "# get last block by table/tx type\n",
        "sql = {}\n",
        "last_blocks = {}\n",
        "for txtype in txtypes:\n",
        "    sql[txtype] = f\"select max(\\\"blockNumber\\\")+1 as block_number from financials.{txtype};\"\n",
        "    last_blocks[txtype] = pd.read_sql_query(sql[txtype], conn).iloc[0]['block_number']\n",
        "\n",
        "# check whether addresses is new in each table\n",
        "sql2 = {}\n",
        "add_check = {}\n",
        "for txtype in txtypes:\n",
        "    add_check[txtype] = {}\n",
        "    \n",
        "    for address in addresses.values():\n",
        "        add_check[txtype][address] = 0\n",
        "        sql2[address] = f\"select count(*) from financials.{txtype} where \\\"from\\\" = \\'{address.lower()}\\' or \\\"to\\\" = \\'{address.lower()}\\'\"\n",
        "        add_check[txtype][address] += pd.read_sql_query(sql2[address], conn).iloc[0]['count']\n",
        "\n",
        "\n",
        "cur.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm7hr_izKTxQ"
      },
      "source": [
        "# Requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "DVQL0VNFIBQ3",
        "outputId": "bee82b31-11fd-40ac-8432-6c5d7b4df8e4"
      },
      "outputs": [],
      "source": [
        "ETHERSCAN_APIKEY = os.environ.get('ETHERSCAN_APIKEY')\n",
        "\n",
        "dfs = {}\n",
        "merge = []\n",
        "# get data from etherscan api\n",
        "for txtype in txtypes:\n",
        "    for address in addresses.values():\n",
        "        if add_check[txtype][address] == 0: # if address is new, start block = 0\n",
        "            payload = {\n",
        "                'module': 'account',\n",
        "                'action': txtypes[txtype],\n",
        "                'address': address,\n",
        "                'startblock': '0',\n",
        "                'endblock': '999999999',\n",
        "                'sort': 'asc',\n",
        "                'apikey': ETHERSCAN_APIKEY\n",
        "            }\n",
        "        else: # else, use last block from database\n",
        "            payload = {\n",
        "                'module': 'account',\n",
        "                'action': txtypes[txtype],\n",
        "                'address': address,\n",
        "                'startblock': last_blocks[txtype],\n",
        "                'endblock': '999999999',\n",
        "                'sort': 'asc',\n",
        "                'apikey': ETHERSCAN_APIKEY\n",
        "            }\n",
        "\n",
        "        r = requests.get('https://api.etherscan.io/api', params=payload)\n",
        "        response = json.loads(r.text)['result']\n",
        "        merge.append(pd.DataFrame.from_dict(response))\n",
        "\n",
        "    dfs[txtype] = pd.concat(merge) # store all merged data in a df\n",
        "    dfs[txtype] = dfs[txtype].drop_duplicates() # remove duplicates (txs between our own wallets)\n",
        "    merge = [] # reset merge array to store new txtype data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save to CSVs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------\n",
        "# export data to CSVs\n",
        "for df in dfs:\n",
        "    dfs[df].to_csv('outputs/' + df + '.csv', index=False)\n",
        "\n",
        "addressdf = pd.DataFrame({'name': addresses.keys(),'address': addresses.values()})\n",
        "addressdf.to_csv('outputs/addresses.csv', index=False)\n",
        "# ----------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send Data to Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New rows:\n",
            "no new data for: normal\n",
            "New rows:\n",
            "no new data for: erc20\n",
            "New rows:\n",
            "no new data for: nfts\n",
            "New rows:\n",
            "no new data for: internal\n"
          ]
        }
      ],
      "source": [
        "import psycopg2.extras as extras\n",
        "\n",
        "# calculate how many rows of new data are to be inserted\n",
        "for df in dfs:\n",
        "    data_check = 0\n",
        "    data_check += len(dfs[df].index)\n",
        "\n",
        "    print('New rows:')\n",
        "    if data_check == 0:\n",
        "        print('no new data for: ' + df)\n",
        "    else:\n",
        "        print(df + ' - ' + str(len(dfs[df].index)))\n",
        "\n",
        "\n",
        "if data_check != 0:\n",
        "    # send data\n",
        "    cursor = conn.cursor()\n",
        "    for txtype in txtypes:\n",
        "        # Create a list of tupples from the dataframe values\n",
        "        tuples = [tuple(x) for x in dfs[txtype].to_numpy()]\n",
        "        # Comma-separated dataframe columns\n",
        "        cols = '\\\",\\\"'.join(list(dfs[txtype].columns))\n",
        "        # SQL quert to execute\n",
        "        query  = \"INSERT INTO %s(\\\"%s\\\") VALUES %%s\" % ('financials.'+ txtype, cols)\n",
        "        # print(query)\n",
        "        cursor = conn.cursor()\n",
        "        try:\n",
        "            extras.execute_values(cursor, query, tuples)\n",
        "            conn.commit()\n",
        "        except (Exception, psycopg2.DatabaseError) as error:\n",
        "            print(\"Error: %s\" % error)\n",
        "            conn.rollback()\n",
        "\n",
        "    print(\"Data uploaded to database.\")\n",
        "    cursor.close()\n",
        "    conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Fingerprints.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
